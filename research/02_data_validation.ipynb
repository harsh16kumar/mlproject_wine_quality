{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56d97501",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb07c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/mlproject_wine_quality'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b583ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    unzip_data_path: Path\n",
    "    STATUS_FILE: Path\n",
    "    schema_file_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bfe7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wine_quality_predictor.constants import *\n",
    "from wine_quality_predictor.utils.common import read_yaml, make_directory\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Path = CONFIG_FILE_PATH,\n",
    "        params_filepath: Path = PARAMS_FILE_PATH,\n",
    "        schema_filepath: Path = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config_filepath = config_filepath\n",
    "        self.params_filepath = params_filepath\n",
    "        self.schema_filepath = schema_filepath\n",
    "\n",
    "        self.config = read_yaml(Path(self.config_filepath))\n",
    "        self.params = read_yaml(Path(self.params_filepath))\n",
    "        self.schema = read_yaml(Path(self.schema_filepath))\n",
    "\n",
    "        make_directory(Path(self.config.artifacts_root))\n",
    "\n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "\n",
    "        return DataValidationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            unzip_data_path=Path(config.unzip_data_path),\n",
    "            STATUS_FILE=Path(config.status_file),\n",
    "            schema_file_path=Path(config.schema_file_path)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3ce413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# from src.<your_project>.entity.config_entity import DataValidationConfig\n",
    "from wine_quality_predictor.utils.common import read_yaml, save_json\n",
    "from wine_quality_predictor import logger\n",
    "\n",
    "\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "        self.schema = read_yaml(self.config.schema_file_path)\n",
    "\n",
    "    def validate_all_columns(self) -> bool:\n",
    "        try:\n",
    "            file = self.config.unzip_data_path\n",
    "            # print(file)\n",
    "            # print(str(file).endswith(\".csv\"))\n",
    "            if str(file).endswith(\".csv\"):\n",
    "                df = pd.read_csv(file, delimiter=';', quotechar='\"')\n",
    "                df_columns = df.columns.tolist()\n",
    "                schema_columns = list(self.schema[\"columns\"].keys())\n",
    "                # print(df_columns)\n",
    "\n",
    "                if df_columns != schema_columns:\n",
    "                    raise Exception(\"Schema mismatch: columns do not match.\")\n",
    "\n",
    "            logger.info(\"All columns are valid.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Validation error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def validate_null_values(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks for any missing (null) values in the dataset.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            file = str(self.config.unzip_data_path)\n",
    "            if file.endswith(\".csv\"):\n",
    "                df = pd.read_csv(file)\n",
    "                if df.isnull().values.any():\n",
    "                    logger.warning(f\"Missing values found in {file}\")\n",
    "                    return False\n",
    "            logger.info(\"No missing values detected.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Null value validation error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def validate_data_types(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks that columns have the correct data types according to schema.yaml.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            file = str(self.config.unzip_data_path)\n",
    "            if file.endswith(\".csv\"):\n",
    "                \n",
    "                df = pd.read_csv(file , delimiter=';', quotechar='\"')\n",
    "                df.columns = df.columns.str.strip()  # Strips leading and trailing spaces from column names\n",
    "                for col, expected_type in self.schema[\"columns\"].items():\n",
    "                    # print(\"standing outside loop\")\n",
    "                    print(\"standing outside loop\")\n",
    "                    print(\"came out brooooo\")\n",
    "                    if df[col].dtype == expected_type:\n",
    "                        print(\"reaced inside loop\")\n",
    "                        logger.warning(f\"Data type mismatch: Column '{col}' in {file} has incorrect data type.\")\n",
    "                        return False\n",
    "                    print(\"\")\n",
    "            logger.info(\"All columns have correct data types.\")\n",
    "            return True\n",
    "        except KeyError as e:\n",
    "                    logger.error(f\"Column '{col}' is missing from the CSV file: {e}\")\n",
    "                    return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data type validation error: {e}\")\n",
    "            return False\n",
    "\n",
    "    # def validate_duplicates(self) -> bool:\n",
    "    #     # \"\"\"\n",
    "    #     # Checks for any duplicate rows in the dataset.\n",
    "    #     # \"\"\"\n",
    "    #     # try:\n",
    "    #     #     file = str(self.config.unzip_data_path)\n",
    "    #     #     if file.endswith(\".csv\"):\n",
    "    #     #         df = pd.read_csv(file)\n",
    "    #     #         if df.duplicated().any():\n",
    "    #     #             logger.warning(f\"Duplicates found in {file}\")\n",
    "    #     #             return False\n",
    "    #     #     logger.info(\"No duplicate rows found.\")\n",
    "    #     #     return True\n",
    "    #     # except Exception as e:\n",
    "    #     #     logger.error(f\"Duplicate validation error: {e}\")\n",
    "    #     #     return False\n",
    "    #     return True\n",
    "\n",
    "    def remove_outliers_iqr(self,df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "        for col in columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            original_size = df.shape[0]\n",
    "            df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "            logger.info(f\"Removed outliers from {col}: {original_size - df.shape[0]} rows removed.\")\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def save_validation_status(self, status: bool):\n",
    "        with open(self.config.STATUS_FILE, 'w') as f:\n",
    "            f.write(f\"Validation status: {status}\")\n",
    "        logger.info(f\"Validation status saved to {self.config.STATUS_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de5fde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.<your_project>.config.configuration import ConfigurationManager\n",
    "# from src.<your_project>.components.data_validation import DataValidation\n",
    "\n",
    "from wine_quality_predictor import logger\n",
    "\n",
    "STAGE_NAME = \"Data Validation\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        logger.info(f\">>>>>> Stage {STAGE_NAME} started <<<<<<\")\n",
    "        config = ConfigurationManager().get_data_validation_config()\n",
    "        validation = DataValidation(config)\n",
    "\n",
    "\n",
    "        df = pd.read_csv(str(\"artifacts/data_ingestion/unzipped_data/winequality-red.csv\"))\n",
    "        df.head(5)\n",
    "        columns_to_clean = [\n",
    "            \"chlorides\",\n",
    "            \"residual sugar\",\n",
    "            \"free sulfur dioxide\",\n",
    "            \"total sulfur dioxide\"\n",
    "        ]\n",
    "        df_cleaned = validation.remove_outliers_iqr(df, columns_to_clean)\n",
    "\n",
    "        # Optional: Save cleaned data\n",
    "        df_cleaned.to_csv(\"artifacts/data_ingestion/unzipped_data/winequality-red.csv\", index=False)\n",
    "        logger.info(\"Saved cleaned data to artifacts/data_ingestion/unzipped_data/winequality-red.csv\")\n",
    "        \n",
    "        column_status = validation.validate_all_columns()\n",
    "        null_status = validation.validate_null_values()\n",
    "        # data_type_status = validation.validate_data_types()\n",
    "        # duplicate_status = validation.validate_duplicates()\n",
    "\n",
    "        final_status = column_status and null_status\n",
    "        validation.save_validation_status(final_status)\n",
    "\n",
    "        logger.info(f\">>>>>> Stage {STAGE_NAME} completed <<<<<<\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error in stage {STAGE_NAME}: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "288c423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-13 08:21:56,760] INFO - 4037898294 - >>>>>> Stage Data Validation started <<<<<<\n",
      "[2025-04-13 08:21:56,767] INFO - common - Loaded YAML file from: config/config.yaml\n",
      "[2025-04-13 08:21:56,771] INFO - common - Loaded YAML file from: params.yaml\n",
      "[2025-04-13 08:21:56,778] INFO - common - Loaded YAML file from: schema.yaml\n",
      "[2025-04-13 08:21:56,779] INFO - common - Created directory: artifacts\n",
      "[2025-04-13 08:21:56,781] INFO - common - Loaded YAML file from: schema.yaml\n",
      "[2025-04-13 08:21:56,789] INFO - 2221646075 - Removed outliers from chlorides: 112 rows removed.\n",
      "[2025-04-13 08:21:56,792] INFO - 2221646075 - Removed outliers from residual sugar: 137 rows removed.\n",
      "[2025-04-13 08:21:56,795] INFO - 2221646075 - Removed outliers from free sulfur dioxide: 26 rows removed.\n",
      "[2025-04-13 08:21:56,797] INFO - 2221646075 - Removed outliers from total sulfur dioxide: 55 rows removed.\n",
      "[2025-04-13 08:21:56,817] INFO - 4037898294 - Saved cleaned data to artifacts/data_ingestion/unzipped_data/winequality-red.csv\n",
      "[2025-04-13 08:21:56,823] ERROR - 2221646075 - Validation error: Schema mismatch: columns do not match.\n",
      "[2025-04-13 08:21:56,829] INFO - 2221646075 - No missing values detected.\n",
      "[2025-04-13 08:21:56,831] INFO - 2221646075 - Validation status saved to artifacts/data_validation/status.txt\n",
      "[2025-04-13 08:21:56,831] INFO - 4037898294 - >>>>>> Stage Data Validation completed <<<<<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6f3d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema = read_yaml(Path(SCHEMA_FILE_PATH))\n",
    "# value = schema[\"columns\"].get('fixed acidity')\n",
    "# file = \"artifacts/data_ingestion/unzipped_data/winequality-red.csv\"\n",
    "# df = pd.read_csv(file, delimiter=';', quotechar='\"')\n",
    "# # df['fixed acidity'].dtype == value\n",
    "# for col, expected_type in schema[\"columns\"].items():\n",
    "#         print(col,df[col].dtype != expected_type)\n",
    "#     # print(col,expected_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
