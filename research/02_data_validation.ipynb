{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56d97501",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbb07c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/mlproject_wine_quality'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b583ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    unzip_data_path: Path\n",
    "    STATUS_FILE: Path\n",
    "    schema_file_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bfe7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wine_quality_predictor.constants import *\n",
    "from wine_quality_predictor.utils.common import read_yaml, make_directory\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Path = CONFIG_FILE_PATH,\n",
    "        params_filepath: Path = PARAMS_FILE_PATH,\n",
    "        schema_filepath: Path = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config_filepath = config_filepath\n",
    "        self.params_filepath = params_filepath\n",
    "        self.schema_filepath = schema_filepath\n",
    "\n",
    "        self.config = read_yaml(Path(self.config_filepath))\n",
    "        self.params = read_yaml(Path(self.params_filepath))\n",
    "        self.schema = read_yaml(Path(self.schema_filepath))\n",
    "\n",
    "        make_directory(Path(self.config.artifacts_root))\n",
    "\n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "\n",
    "        return DataValidationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            unzip_data_path=Path(config.unzip_data_path),\n",
    "            STATUS_FILE=Path(config.status_file),\n",
    "            schema_file_path=Path(config.schema_file_path)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d3ce413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# from src.<your_project>.entity.config_entity import DataValidationConfig\n",
    "from wine_quality_predictor.utils.common import read_yaml, save_json\n",
    "from wine_quality_predictor import logger\n",
    "\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "        self.schema = read_yaml(self.config.schema_file_path)\n",
    "\n",
    "    def validate_all_columns(self) -> bool:\n",
    "        try:\n",
    "            file = self.config.unzip_data_path\n",
    "            # print(file)\n",
    "            # print(str(file).endswith(\".csv\"))\n",
    "            if str(file).endswith(\".csv\"):\n",
    "                df = pd.read_csv(file, delimiter=';', quotechar='\"')\n",
    "                df_columns = df.columns.tolist()\n",
    "                schema_columns = list(self.schema[\"columns\"].keys())\n",
    "                # print(df_columns)\n",
    "\n",
    "                if df_columns != schema_columns:\n",
    "                    raise Exception(\"Schema mismatch: columns do not match.\")\n",
    "\n",
    "            logger.info(\"All columns are valid.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Validation error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def validate_null_values(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks for any missing (null) values in the dataset.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            file = str(self.config.unzip_data_path)\n",
    "            if file.endswith(\".csv\"):\n",
    "                df = pd.read_csv(file)\n",
    "                if df.isnull().values.any():\n",
    "                    logger.warning(f\"Missing values found in {file}\")\n",
    "                    return False\n",
    "            logger.info(\"No missing values detected.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Null value validation error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def validate_data_types(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks that columns have the correct data types according to schema.yaml.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            file = str(self.config.unzip_data_path)\n",
    "            if file.endswith(\".csv\"):\n",
    "                \n",
    "                df = pd.read_csv(file)\n",
    "                df.columns = df.columns.str.strip()  # Strips leading and trailing spaces from column names\n",
    "                for col, expected_type in self.schema[\"columns\"].items():\n",
    "                    # print(\"standing outside loop\")\n",
    "                    print(\"standing outside loop\")\n",
    "                    print(\"came out brooooo\")\n",
    "                    if df[col].dtype == expected_type:\n",
    "                        print(\"reaced inside loop\")\n",
    "                        logger.warning(f\"Data type mismatch: Column '{col}' in {file} has incorrect data type.\")\n",
    "                        return False\n",
    "                    print(\"\")\n",
    "            logger.info(\"All columns have correct data types.\")\n",
    "            return True\n",
    "        except KeyError as e:\n",
    "                    logger.error(f\"Column '{col}' is missing from the CSV file: {e}\")\n",
    "                    return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data type validation error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def validate_duplicates(self) -> bool:\n",
    "        # \"\"\"\n",
    "        # Checks for any duplicate rows in the dataset.\n",
    "        # \"\"\"\n",
    "        # try:\n",
    "        #     file = str(self.config.unzip_data_path)\n",
    "        #     if file.endswith(\".csv\"):\n",
    "        #         df = pd.read_csv(file)\n",
    "        #         if df.duplicated().any():\n",
    "        #             logger.warning(f\"Duplicates found in {file}\")\n",
    "        #             return False\n",
    "        #     logger.info(\"No duplicate rows found.\")\n",
    "        #     return True\n",
    "        # except Exception as e:\n",
    "        #     logger.error(f\"Duplicate validation error: {e}\")\n",
    "        #     return False\n",
    "        return True\n",
    "\n",
    "    def save_validation_status(self, status: bool):\n",
    "        with open(self.config.STATUS_FILE, 'w') as f:\n",
    "            f.write(f\"Validation status: {status}\")\n",
    "        logger.info(f\"Validation status saved to {self.config.STATUS_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "de5fde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.<your_project>.config.configuration import ConfigurationManager\n",
    "# from src.<your_project>.components.data_validation import DataValidation\n",
    "\n",
    "from wine_quality_predictor import logger\n",
    "\n",
    "STAGE_NAME = \"Data Validation\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        logger.info(f\">>>>>> Stage {STAGE_NAME} started <<<<<<\")\n",
    "\n",
    "        config = ConfigurationManager().get_data_validation_config()\n",
    "        validation = DataValidation(config)\n",
    "\n",
    "        column_status = validation.validate_all_columns()\n",
    "        null_status = validation.validate_null_values()\n",
    "        data_type_status = validation.validate_data_types()\n",
    "        duplicate_status = validation.validate_duplicates()\n",
    "\n",
    "        final_status = column_status and null_status and data_type_status and duplicate_status\n",
    "\n",
    "        validation.save_validation_status(final_status)\n",
    "\n",
    "        logger.info(f\">>>>>> Stage {STAGE_NAME} completed <<<<<<\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error in stage {STAGE_NAME}: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "288c423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-10 15:35:33,107] INFO - 388338840 - >>>>>> Stage Data Validation started <<<<<<\n",
      "[2025-04-10 15:35:33,112] INFO - common - Loaded YAML file from: config/config.yaml\n",
      "[2025-04-10 15:35:33,113] INFO - common - Loaded YAML file from: params.yaml\n",
      "[2025-04-10 15:35:33,115] INFO - common - Loaded YAML file from: schema.yaml\n",
      "[2025-04-10 15:35:33,116] INFO - common - Created directory: artifacts\n",
      "[2025-04-10 15:35:33,119] INFO - common - Loaded YAML file from: schema.yaml\n",
      "[2025-04-10 15:35:33,123] INFO - 632903387 - All columns are valid.\n",
      "[2025-04-10 15:35:33,126] INFO - 632903387 - No missing values detected.\n",
      "[2025-04-10 15:35:33,131] ERROR - 632903387 - Column 'fixed acidity' is missing from the CSV file: 'fixed acidity'\n",
      "[2025-04-10 15:35:33,133] INFO - 632903387 - Validation status saved to artifacts/data_validation/status.txt\n",
      "[2025-04-10 15:35:33,135] INFO - 388338840 - >>>>>> Stage Data Validation completed <<<<<<\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing outside loop\n",
      "came out brooooo\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f6f3d44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-10 15:29:04,576] INFO - common - Loaded YAML file from: schema.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity False\n",
      "volatile acidity False\n",
      "citric acid False\n",
      "residual sugar False\n",
      "chlorides False\n",
      "free sulfur dioxide False\n",
      "total sulfur dioxide False\n",
      "density False\n",
      "pH False\n",
      "sulphates False\n",
      "alcohol False\n",
      "quality False\n"
     ]
    }
   ],
   "source": [
    "schema = read_yaml(Path(SCHEMA_FILE_PATH))\n",
    "value = schema[\"columns\"].get('fixed acidity')\n",
    "file = \"artifacts/data_ingestion/unzipped_data/winequality-red.csv\"\n",
    "df = pd.read_csv(file, delimiter=';', quotechar='\"')\n",
    "# df['fixed acidity'].dtype == value\n",
    "for col, expected_type in schema[\"columns\"].items():\n",
    "        print(col,df[col].dtype != expected_type)\n",
    "    # print(col,expected_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
