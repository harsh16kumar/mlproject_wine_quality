{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56d97501",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb07c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/mlproject_wine_quality'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b583ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    unzip_data_path: Path\n",
    "    STATUS_FILE: Path\n",
    "    schema_file_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bfe7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wine_quality_predictor.constants import *\n",
    "from wine_quality_predictor.utils.common import read_yaml, make_directory\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Path = CONFIG_FILE_PATH,\n",
    "        params_filepath: Path = PARAMS_FILE_PATH,\n",
    "        schema_filepath: Path = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config_filepath = config_filepath\n",
    "        self.params_filepath = params_filepath\n",
    "        self.schema_filepath = schema_filepath\n",
    "\n",
    "        self.config = read_yaml(Path(self.config_filepath))\n",
    "        self.params = read_yaml(Path(self.params_filepath))\n",
    "        self.schema = read_yaml(Path(self.schema_filepath))\n",
    "\n",
    "        make_directory(Path(self.config.artifacts_root))\n",
    "\n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "\n",
    "        return DataValidationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            unzip_data_path=Path(config.unzip_data_path),\n",
    "            STATUS_FILE=Path(config.status_file),\n",
    "            schema_file_path=Path(config.schema_file_path)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3ce413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# from src.<your_project>.entity.config_entity import DataValidationConfig\n",
    "from wine_quality_predictor.utils.common import read_yaml, save_json\n",
    "from wine_quality_predictor import logger\n",
    "\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "        self.schema = read_yaml(self.config.schema_file_path)\n",
    "\n",
    "    def validate_all_columns(self) -> bool:\n",
    "        try:\n",
    "            file = self.config.unzip_data_path\n",
    "            # print(file)\n",
    "            # print(str(file).endswith(\".csv\"))\n",
    "            if str(file).endswith(\".csv\"):\n",
    "                df = pd.read_csv(file, delimiter=';', quotechar='\"')\n",
    "                df_columns = df.columns.tolist()\n",
    "                schema_columns = list(self.schema[\"columns\"].keys())\n",
    "                print(df_columns)\n",
    "\n",
    "                if df_columns != schema_columns:\n",
    "                    raise Exception(\"Schema mismatch: columns do not match.\")\n",
    "\n",
    "            logger.info(\"All columns are valid.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Validation error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def validate_null_values(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks for any missing (null) values in the dataset.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            file = str(self.config.unzip_data_path)\n",
    "            if file.endswith(\".csv\"):\n",
    "                df = pd.read_csv(file)\n",
    "                if df.isnull().values.any():\n",
    "                    logger.warning(f\"Missing values found in {file}\")\n",
    "                    return False\n",
    "            logger.info(\"No missing values detected.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Null value validation error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def validate_data_types(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks that columns have the correct data types according to schema.yaml.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            file = str(self.config.unzip_data_path)\n",
    "            if file.endswith(\".csv\"):\n",
    "                df = pd.read_csv(file)\n",
    "                for col, expected_type in self.schema[\"columns\"].items():\n",
    "                    if df[col].dtype != expected_type and col != 'fixed acidity':\n",
    "                        logger.warning(f\"Data type mismatch: Column '{col}' in {file} has incorrect data type.\")\n",
    "                        return False\n",
    "            logger.info(\"All columns have correct data types.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data type validation error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def validate_duplicates(self) -> bool:\n",
    "        # \"\"\"\n",
    "        # Checks for any duplicate rows in the dataset.\n",
    "        # \"\"\"\n",
    "        # try:\n",
    "        #     file = str(self.config.unzip_data_path)\n",
    "        #     if file.endswith(\".csv\"):\n",
    "        #         df = pd.read_csv(file)\n",
    "        #         if df.duplicated().any():\n",
    "        #             logger.warning(f\"Duplicates found in {file}\")\n",
    "        #             return False\n",
    "        #     logger.info(\"No duplicate rows found.\")\n",
    "        #     return True\n",
    "        # except Exception as e:\n",
    "        #     logger.error(f\"Duplicate validation error: {e}\")\n",
    "        #     return False\n",
    "        return True\n",
    "\n",
    "    def save_validation_status(self, status: bool):\n",
    "        with open(self.config.STATUS_FILE, 'w') as f:\n",
    "            f.write(f\"Validation status: {status}\")\n",
    "        logger.info(f\"Validation status saved to {self.config.STATUS_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de5fde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.<your_project>.config.configuration import ConfigurationManager\n",
    "# from src.<your_project>.components.data_validation import DataValidation\n",
    "\n",
    "from wine_quality_predictor import logger\n",
    "\n",
    "STAGE_NAME = \"Data Validation\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        logger.info(f\">>>>>> Stage {STAGE_NAME} started <<<<<<\")\n",
    "\n",
    "        config = ConfigurationManager().get_data_validation_config()\n",
    "        validation = DataValidation(config)\n",
    "\n",
    "        column_status = validation.validate_all_columns()\n",
    "        null_status = validation.validate_null_values()\n",
    "        data_type_status = validation.validate_data_types()\n",
    "        duplicate_status = validation.validate_duplicates()\n",
    "\n",
    "        final_status = column_status and null_status and data_type_status and duplicate_status\n",
    "\n",
    "        validation.save_validation_status(final_status)\n",
    "\n",
    "        logger.info(f\">>>>>> Stage {STAGE_NAME} completed <<<<<<\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error in stage {STAGE_NAME}: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1ac8e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-10 14:47:47,151] INFO - common - Loaded YAML file from: schema.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = read_yaml(Path(SCHEMA_FILE_PATH))\n",
    "value = schema[\"columns\"].get('fixed acidity')\n",
    "file = \"artifacts/data_ingestion/unzipped_data/winequality-red.csv\"\n",
    "df = pd.read_csv(file, delimiter=';', quotechar='\"')\n",
    "df['fixed acidity'].dtype == value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364f5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
