{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30770fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dd476c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/mlproject_wine_quality'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "# os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cc8cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    scaler_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2e25cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wine_quality_predictor.constants import *\n",
    "from wine_quality_predictor.utils.common import read_yaml, make_directory\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath: Path = CONFIG_FILE_PATH,\n",
    "        params_filepath: Path = PARAMS_FILE_PATH,\n",
    "        schema_filepath: Path = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        self.config_filepath = config_filepath\n",
    "        self.params_filepath = params_filepath\n",
    "        self.schema_filepath = schema_filepath\n",
    "\n",
    "        self.config = read_yaml(Path(self.config_filepath))\n",
    "        self.params = read_yaml(Path(self.params_filepath))\n",
    "        self.schema = read_yaml(Path(self.schema_filepath))\n",
    "\n",
    "        make_directory(Path(self.config.artifacts_root))\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        return DataTransformationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            data_path=Path(config.data_path),\n",
    "            scaler_path=Path(config.scaler_path)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9092b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from wine_quality_predictor.entity.config_entity import DataTransformationConfig\n",
    "from wine_quality_predictor.utils.common import make_directory, save_bin\n",
    "from wine_quality_predictor import logger\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def transform_and_split(self):\n",
    "        logger.info(\"Reading dataset for transformation and splitting...\")\n",
    "        df = pd.read_csv(self.config.data_path)\n",
    "        # df = pd.read_csv(self.config.data_path , delimiter=\";\",quotechar='\"')\n",
    "\n",
    "        # if df.isnull().sum().sum() > 0:\n",
    "        #     logger.warning(\"Missing values found. Filling with mean...\")\n",
    "        #     df = df.fillna(df.mean())\n",
    "\n",
    "        logger.info(\"Splitting data into train and test...\")\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        \n",
    "\n",
    "        # X_train = train_df.drop(\"quality\", axis=1)\n",
    "        # y_train = train_df[\"quality\"]\n",
    "        # X_test = test_df.drop(\"quality\", axis=1)\n",
    "        # y_test = test_df[\"quality\"]\n",
    "\n",
    "        # logger.info(\"Fitting scaler on training data and transforming...\")\n",
    "        # scaler = StandardScaler()\n",
    "        # X_train_scaled = scaler.fit_transform(X_train)\n",
    "        # X_test_scaled = scaler.transform(X_test)\n",
    "        # # X_train_scaled = X_train\n",
    "        # # X_test_scaled = X_test\n",
    "\n",
    "        # train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "        # train_scaled[\"quality\"] = y_train.reset_index(drop=True)\n",
    "\n",
    "        # test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "        # test_scaled[\"quality\"] = y_test.reset_index(drop=True)\n",
    "\n",
    "        logger.info(\"Creating output directories and saving files...\")\n",
    "        make_directory(self.config.root_dir)\n",
    "\n",
    "        train_path = self.config.root_dir / \"train.csv\"\n",
    "        test_path = self.config.root_dir / \"test.csv\"\n",
    "\n",
    "        train_df.to_csv(train_path, index=False)\n",
    "        train_df.to_csv(test_path, index=False)\n",
    "        # train_scaled.to_csv(train_path, index=False)\n",
    "        # test_scaled.to_csv(test_path, index=False)\n",
    "\n",
    "        # save_bin(self.config.scaler_path, scaler)\n",
    "\n",
    "        logger.info(f\"Train and test data saved to {self.config.root_dir}\")\n",
    "        logger.info(f\"Scaler saved at {self.config.scaler_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbc1482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.<your_project>.config.configuration import ConfigurationManager\n",
    "# from src.<your_project>.components.data_transformation import DataTransformation\n",
    "from wine_quality_predictor import logger\n",
    "\n",
    "STAGE_NAME = \"Data Transformation\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        logger.info(f\">>>>>> Stage {STAGE_NAME} started <<<<<<\")\n",
    "        config = ConfigurationManager().get_data_transformation_config()\n",
    "        transformer = DataTransformation(config)\n",
    "        transformer.transform_and_split()\n",
    "        logger.info(f\">>>>>> Stage {STAGE_NAME} completed <<<<<<\\n\")\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error in stage {STAGE_NAME}: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a814f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-13 07:57:27,437] INFO - 2021950657 - >>>>>> Stage Data Transformation started <<<<<<\n",
      "[2025-04-13 07:57:27,443] INFO - common - Loaded YAML file from: config/config.yaml\n",
      "[2025-04-13 07:57:27,445] INFO - common - Loaded YAML file from: params.yaml\n",
      "[2025-04-13 07:57:27,448] INFO - common - Loaded YAML file from: schema.yaml\n",
      "[2025-04-13 07:57:27,450] INFO - common - Created directory: artifacts\n",
      "[2025-04-13 07:57:27,452] INFO - 2047129445 - Reading dataset for transformation and splitting...\n",
      "[2025-04-13 07:57:27,456] INFO - 2047129445 - Splitting data into train and test...\n",
      "[2025-04-13 07:57:27,458] INFO - 2047129445 - Creating output directories and saving files...\n",
      "[2025-04-13 07:57:27,459] INFO - common - Created directory: artifacts/data_transformation\n",
      "[2025-04-13 07:57:27,485] INFO - 2047129445 - Train and test data saved to artifacts/data_transformation\n",
      "[2025-04-13 07:57:27,486] INFO - 2047129445 - Scaler saved at artifacts/data_transformation/scaler.pkl\n",
      "[2025-04-13 07:57:27,487] INFO - 2021950657 - >>>>>> Stage Data Transformation completed <<<<<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9456115c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      5\n",
       "1      6\n",
       "2      5\n",
       "3      6\n",
       "4      6\n",
       "      ..\n",
       "912    5\n",
       "913    6\n",
       "914    6\n",
       "915    6\n",
       "916    5\n",
       "Name: quality, Length: 917, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path= \"artifacts/data_transformation/train.csv\"\n",
    "test_data_path= \"artifacts/data_transformation/test.csv\"\n",
    "train_df = pd.read_csv(str(train_data_path))\n",
    "test_df = pd.read_csv(str(test_data_path))\n",
    "X_train = train_df.drop(\"quality\", axis=1)\n",
    "y_train = train_df[\"quality\"]\n",
    "X_test = test_df.drop(\"quality\", axis=1)\n",
    "y_test = test_df[\"quality\"]\n",
    "print(y_train.isna().sum())\n",
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
